# main.py
from __future__ import annotations

from pathlib import Path
from datetime import datetime, timedelta, date
from dateutil.tz import gettz
import argparse
import pandas as pd
from tqdm import tqdm
import os

# --- Suas libs locais ---
from src.recupera_dados_api_dia import get_clima_diario_por_data
from src.recupera_dados_api_hora import get_clima_horario_por_data
from src.processa_dados import processar_clima
from src.upload_s3 import upload_para_s3


TIMEZONE = "America/Sao_Paulo"


# ============================================================
# HELPERS
# ============================================================
def _resolve_base_dir() -> Path:
    """Acha raiz do projeto."""
    here = Path(__file__).resolve().parent
    for base in [here, here.parent]:
        if (base / "data" / "lista_municipios").exists():
            return base
    return here


def _hoje():
    tz = gettz(TIMEZONE)
    return datetime.now(tz).date()


def _d1():
    return _hoje() - timedelta(days=1)


# ---------- STATE FILE ----------
def _state_file(base_dir: Path) -> Path:
    return base_dir / "state" / "last_run.txt"


def _carregar_last_run(base_dir: Path):
    sf = _state_file(base_dir)
    if not sf.exists():
        return None  # primeira execuÃ§Ã£o
    try:
        return datetime.strptime(sf.read_text().strip(), "%Y-%m-%d").date()
    except:
        return None


def _salvar_last_run(base_dir: Path, d: date):
    sf = _state_file(base_dir)
    sf.parent.mkdir(parents=True, exist_ok=True)
    sf.write_text(d.strftime("%Y-%m-%d"))


def _datas_pendentes(base_dir: Path):
    last_run = _carregar_last_run(base_dir)
    d1 = _d1()

    # primeira execuÃ§Ã£o â†’ processa sÃ³ D-1
    if last_run is None:
        return [d1]

    dias = []
    dia = last_run + timedelta(days=1)
    while dia <= d1:
        dias.append(dia)
        dia += timedelta(days=1)

    return dias


# ============================================================
# COLETA DIÃRIA
# ============================================================
def coleta_diaria(base_dir: Path, dia: date):
    dt_str = dia.strftime("%Y-%m-%d")
    path_lista = base_dir / "data" / "lista_municipios" / "lista_mun.csv"
    path_ext_raw_diario = base_dir / "data" / "raw" / "diario"

    df_cidades = pd.read_csv(path_lista, sep=";")
    print(f"ğŸ“… (DIÃRIO) Coletando {dt_str} para {len(df_cidades)} municÃ­pios")

    dados = []
    falhas = 0

    for _, row in tqdm(df_cidades.iterrows(), total=df_cidades.shape[0]):
        try:
            clima = get_clima_diario_por_data(row["latitude"], row["longitude"], dt_str)
            df_clima = processar_clima(clima, row)
            dados.append(df_clima)
        except Exception as e:
            falhas += 1
            print(f"Falha em {row['nome']} ({row['nome_uf']}): {e}")

    if not dados:
        print("âŒ Nenhum dado diÃ¡rio coletado.")
        return None

    df_final = pd.concat(dados, ignore_index=True)

    os.makedirs(path_ext_raw_diario, exist_ok=True)
    saida = path_ext_raw_diario / f"dados_climaticos_diarios_{dia.strftime('%Y%m%d')}.parquet"

    df_final.to_parquet(saida, index=False, engine="pyarrow", compression="snappy")

    print(f"âœ… DiÃ¡rio salvo em: {saida}")
    if falhas:
        print(f"AtenÃ§Ã£o: {falhas} municÃ­pio(s) falharam (diÃ¡rio).")

    return saida


# ============================================================
# COLETA HORÃRIA
# ============================================================
def coleta_horaria(base_dir: Path, dia: date):
    dt_str = dia.strftime("%Y-%m-%d")
    dt_file = dia.strftime("%Y%m%d")

    path_lista = base_dir / "data" / "lista_municipios" / "lista_mun.csv"
    path_ext_raw_horario = base_dir / "data" / "raw" / "horario"

    df_cidades = pd.read_csv(path_lista, sep=";")
    print(f"â±ï¸ (HORÃRIO) Coletando {dt_str} para {len(df_cidades)} municÃ­pios")

    dados = []
    falhas = 0

    for _, row in tqdm(df_cidades.iterrows(), total=df_cidades.shape[0]):
        try:
            df_hora = get_clima_horario_por_data(row["latitude"], row["longitude"], dt_str, TIMEZONE)
            df_hora["municipio"] = row["nome"]
            df_hora["uf"] = row["nome_uf"]
            df_hora["latitude"] = row["latitude"]
            df_hora["longitude"] = row["longitude"]
            dados.append(df_hora)
        except Exception as e:
            falhas += 1
            print(f"Falha em {row['nome']}: {e}")

    if not dados:
        print("âŒ Nenhum dado horÃ¡rio coletado.")
        return None

    df_final = pd.concat(dados, ignore_index=True)

    # renomeia
    rename_cols = {
        "time": "data_hora",
        "temperature_2m": "temperatura_c",
        "relative_humidity_2m": "umidade_relativa",
        "precipitation": "precipitacao_mm",
        "wind_speed_10m": "velocidade_vento_ms",
    }
    df_final.rename(columns=rename_cols, inplace=True)

    colunas = [
        "data_hora", "municipio", "uf", "latitude", "longitude",
        "temperatura_c", "umidade_relativa", "precipitacao_mm",
        "velocidade_vento_ms"
    ]
    df_final = df_final[[c for c in colunas if c in df_final.columns]]

    os.makedirs(path_ext_raw_horario, exist_ok=True)
    saida = path_ext_raw_horario / f"dados_climaticos_horarios_{dt_file}.parquet"

    df_final.to_parquet(saida, index=False, engine="pyarrow", compression="snappy")

    print(f"âœ… HorÃ¡rio salvo em: {saida}")
    if falhas:
        print(f"AtenÃ§Ã£o: {falhas} municÃ­pio(s) falharam (horÃ¡rio).")

    return saida


# ============================================================
# MAIN
# ============================================================
def parse_args():
    p = argparse.ArgumentParser(description="Coleta Open-Meteo â€“ diÃ¡rio/horÃ¡rio/ambos (incremental)")
    p.add_argument("--modo", choices=["diario", "horario", "ambos"], default="ambos")
    return p.parse_args()


def main():
    args = parse_args()
    base_dir = _resolve_base_dir()

    print("ğŸ“ BASE_DIR:", base_dir)

    datas = _datas_pendentes(base_dir)

    if not datas:
        print("Nenhuma data pendente. Nada a fazer.")
        return

    print("ğŸ“… Datas a processar:", [str(d) for d in datas])

    # ----------------------------
    # NOVO: armazenar parquets antes do upload
    # ----------------------------
    arquivos_diarios_gerados = []
    arquivos_horarios_gerados = []

    # =======================================================
    # PARTE 1 â€” COLETA (gera todos os parquets primeiro)
    # =======================================================
    for dia in datas:
        print(f"\n==============================")
        print(f"GERANDO PARQUETS PARA {dia}")
        print(f"==============================")

        # DIÃRIO
        if args.modo in ("diario", "ambos"):
            p1 = coleta_diaria(base_dir, dia)
            if p1:
                arquivos_diarios_gerados.append((p1, dia))

        # HORÃRIO
        if args.modo in ("horario", "ambos"):
            p2 = coleta_horaria(base_dir, dia)
            if p2:
                arquivos_horarios_gerados.append((p2, dia))

    # =======================================================
    # PARTE 2 â€” UPLOAD (somente depois de gerar tudo)
    # =======================================================
    print("\n==============================")
    print("INICIANDO UPLOAD PARA S3â€¦")
    print("==============================")

    # Upload dos diÃ¡rios
    for caminho, dia in arquivos_diarios_gerados:
        print(f"â¬†ï¸  Enviando diÃ¡rio {dia} â†’ {caminho.name}")
        upload_para_s3(
            caminho_local=caminho,
            tipo="diario",
            data_referencia=dia.strftime("%Y-%m-%d")
        )

    # Upload dos horÃ¡rios
    for caminho, dia in arquivos_horarios_gerados:
        print(f"â¬†ï¸  Enviando horÃ¡rio {dia} â†’ {caminho.name}")
        upload_para_s3(
            caminho_local=caminho,
            tipo="horario",
            data_referencia=dia.strftime("%Y-%m-%d")
        )

    # =======================================================
    # PARTE 3 â€” Atualiza o STATE
    # =======================================================
    ultimo_processado = max(datas)
    _salvar_last_run(base_dir, ultimo_processado)

    print(f"\nğŸ“Œ STATE atualizado para {ultimo_processado}")
    print("âœ… Processo concluÃ­do com sucesso!")



if __name__ == "__main__":
    main()
